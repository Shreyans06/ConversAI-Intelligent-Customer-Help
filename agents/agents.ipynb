{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /home/shreyans06/Desktop/ML/LANGCHAIN-DEMO/venv/lib/python3.12/site-packages (from arxiv) (2.32.3)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/shreyans06/Desktop/ML/LANGCHAIN-DEMO/venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/shreyans06/Desktop/ML/LANGCHAIN-DEMO/venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shreyans06/Desktop/ML/LANGCHAIN-DEMO/venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/shreyans06/Desktop/ML/LANGCHAIN-DEMO/venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2024.7.4)\n",
      "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m921.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=0c7df4493b3bd63209bb8d23f49fecfc827f5766c289a11700fc5204da9161ef\n",
      "  Stored in directory: /home/shreyans06/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-2.1.3 feedparser-6.0.11 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wrapper = WikipediaAPIWrapper(top_k_results=1 , doc_content_chars_max= 200)\n",
    "wiki = WikipediaQueryRun(api_wrapper = wiki_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ed3a044d880>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import  RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "document = RecursiveCharacterTextSplitter(chunk_size = 1000 , chunk_overlap = 200).split_documents(docs)\n",
    "vector_db = FAISS.from_documents(document , OllamaEmbeddings())\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever , \"langsmith-search\" , \"Search for information about LangSmith\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1 , doc_content_chars_max= 200)\n",
    "arxiv = ArxivQueryRun(api_wrapper = arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/shreyans06/Desktop/ML/LANGCHAIN-DEMO/venv/lib/python3.12/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith-search', description='Search for information about LangSmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7ed3b83bb6a0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ed3a044d880>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7ed3b83bb7e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ed3a044d880>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki , arxiv , retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n",
      "Python-dotenv could not parse statement starting at line 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOllama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm , tools , prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOllama(), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search for information about LangSmith', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/shreyans06/Desktop/ML/LANGCHAIN-DEMO/venv/lib/python3.12/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith-search', description='Search for information about LangSmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7ed3b83bb6a0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ed3a044d880>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7ed3b83bb7e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ed3a044d880>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executor\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent = agent , tools = tools , verbose= True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "LangSmith is a language model that I am currently trained on, and it's designed to assist with a wide range of tasks, including but not limited to:\n",
      "\n",
      "1. Language Translation: LangSmith can translate text from one language to another, allowing you to communicate with people who speak different languages.\n",
      "2. Text Summarization: LangSmith can summarize long pieces of text into shorter, more digestible versions, saving you time and effort.\n",
      "3. Writing Assistance: LangSmith can help you generate ideas for writing, provide suggestions for improvement, and even write entire paragraphs or articles for you.\n",
      "4. Conversational Dialogue: LangSmith is trained on a wide range of conversations, allowing it to engage in natural-sounding dialogue with you. Whether you're chatting about your day or asking for advice, LangSmith is here to help.\n",
      "5. Knowledge Retrieval: LangSmith has access to a vast amount of knowledge that it can draw upon to answer questions, provide definitions, and more.\n",
      "6. Creative Writing: LangSmith can generate creative writing, such as poetry or short stories, using various styles and genres.\n",
      "7. Language Learning: LangSmith can assist language learners by providing correct grammar and pronunciation, as well as offering suggestions for improvement.\n",
      "8. Chatbot Integration: LangSmith can be integrated into chatbots to provide a more personalized and human-like interaction experience for users.\n",
      "9. Content Generation: LangSmith can generate content, such as articles, blog posts, and social media updates, at scale and in a timely manner.\n",
      "10. Personal Assistant: LangSmith can act as a personal assistant by providing reminders, scheduling appointments, and sending messages on your behalf.\n",
      "\n",
      "These are just a few examples of what LangSmith can do. If you have any specific questions or tasks in mind, feel free to ask and I'll do my best to help!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about LangSmith',\n",
       " 'output': \"\\nLangSmith is a language model that I am currently trained on, and it's designed to assist with a wide range of tasks, including but not limited to:\\n\\n1. Language Translation: LangSmith can translate text from one language to another, allowing you to communicate with people who speak different languages.\\n2. Text Summarization: LangSmith can summarize long pieces of text into shorter, more digestible versions, saving you time and effort.\\n3. Writing Assistance: LangSmith can help you generate ideas for writing, provide suggestions for improvement, and even write entire paragraphs or articles for you.\\n4. Conversational Dialogue: LangSmith is trained on a wide range of conversations, allowing it to engage in natural-sounding dialogue with you. Whether you're chatting about your day or asking for advice, LangSmith is here to help.\\n5. Knowledge Retrieval: LangSmith has access to a vast amount of knowledge that it can draw upon to answer questions, provide definitions, and more.\\n6. Creative Writing: LangSmith can generate creative writing, such as poetry or short stories, using various styles and genres.\\n7. Language Learning: LangSmith can assist language learners by providing correct grammar and pronunciation, as well as offering suggestions for improvement.\\n8. Chatbot Integration: LangSmith can be integrated into chatbots to provide a more personalized and human-like interaction experience for users.\\n9. Content Generation: LangSmith can generate content, such as articles, blog posts, and social media updates, at scale and in a timely manner.\\n10. Personal Assistant: LangSmith can act as a personal assistant by providing reminders, scheduling appointments, and sending messages on your behalf.\\n\\nThese are just a few examples of what LangSmith can do. If you have any specific questions or tasks in mind, feel free to ask and I'll do my best to help!\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Tell me about LangSmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Hello! I'm glad you asked about Machine Learning (ML)! It's a rapidly growing field that's revolutionizing many industries. ML is a subset of Artificial Intelligence (AI) that involves training computer systems to learn from data, without being explicitly programmed. The goal is to enable machines to make predictions or take actions based on patterns they detect in the data.\n",
      "\n",
      "ML has become a hot topic for several reasons:\n",
      "\n",
      "1. Accelerating technological advancements: ML algorithms are driving innovation in areas like image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles. As these technologies improve, we'll see more automation, efficiency, and personalization in various industries.\n",
      "2. Increased data availability: The exponential growth of digital data has created a wealth of opportunities for ML to uncover insights and make predictions. With the rise of IoT devices, social media, and other data-generating sources, there's an abundance of information for ML algorithms to learn from.\n",
      "3. Applications in various industries: ML is being applied in healthcare to diagnose diseases more accurately, in finance to predict stock prices and fraud detection, and in retail to personalize customer experiences. It's also used in security systems to detect anomalies and prevent cyber attacks.\n",
      "4. Improved accuracy: ML models can analyze vast amounts of data and identify patterns that would be difficult or impossible for humans to detect. This leads to increased accuracy in predictions and decision-making, making it an essential tool for many industries.\n",
      "5. Potential for job displacement: While ML offers many benefits, there's also a concern that it could displace certain jobs, particularly those that involve data analysis or repetitive tasks. As ML continues to advance, it's crucial to consider the ethical implications of these changes and prepare workers for new roles.\n",
      "6. Ethical considerations: With ML becoming more pervasive, there are growing concerns about bias in algorithms, privacy issues, and the potential for misuse. It's essential to address these ethical challenges through responsible development and deployment of ML systems.\n",
      "7. Advances in computational power: The rapid growth of computing power has enabled faster and more complex ML models, leading to breakthroughs in various applications.\n",
      "8. Increased investment: The increasing interest in ML has led to a surge in investment in startups and research initiatives, further fueling innovation in the field.\n",
      "9. Government support: Governments worldwide are recognizing the potential of ML and are providing funding and resources to support its development and adoption.\n",
      "10. Exciting developments: The intersection of ML with other technologies like quantum computing, edge AI, and federated learning is leading to new and innovative applications that will continue to shape the field in the years to come.\n",
      "\n",
      "In summary, Machine Learning is a hot topic due to its rapidly growing potential across various industries, improved accuracy, ethical considerations, advances in computational power, increased investment, government support, and exciting developments at the intersection of ML with other technologies.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is ML and why is it a hot topic?',\n",
       " 'output': \"\\nHello! I'm glad you asked about Machine Learning (ML)! It's a rapidly growing field that's revolutionizing many industries. ML is a subset of Artificial Intelligence (AI) that involves training computer systems to learn from data, without being explicitly programmed. The goal is to enable machines to make predictions or take actions based on patterns they detect in the data.\\n\\nML has become a hot topic for several reasons:\\n\\n1. Accelerating technological advancements: ML algorithms are driving innovation in areas like image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles. As these technologies improve, we'll see more automation, efficiency, and personalization in various industries.\\n2. Increased data availability: The exponential growth of digital data has created a wealth of opportunities for ML to uncover insights and make predictions. With the rise of IoT devices, social media, and other data-generating sources, there's an abundance of information for ML algorithms to learn from.\\n3. Applications in various industries: ML is being applied in healthcare to diagnose diseases more accurately, in finance to predict stock prices and fraud detection, and in retail to personalize customer experiences. It's also used in security systems to detect anomalies and prevent cyber attacks.\\n4. Improved accuracy: ML models can analyze vast amounts of data and identify patterns that would be difficult or impossible for humans to detect. This leads to increased accuracy in predictions and decision-making, making it an essential tool for many industries.\\n5. Potential for job displacement: While ML offers many benefits, there's also a concern that it could displace certain jobs, particularly those that involve data analysis or repetitive tasks. As ML continues to advance, it's crucial to consider the ethical implications of these changes and prepare workers for new roles.\\n6. Ethical considerations: With ML becoming more pervasive, there are growing concerns about bias in algorithms, privacy issues, and the potential for misuse. It's essential to address these ethical challenges through responsible development and deployment of ML systems.\\n7. Advances in computational power: The rapid growth of computing power has enabled faster and more complex ML models, leading to breakthroughs in various applications.\\n8. Increased investment: The increasing interest in ML has led to a surge in investment in startups and research initiatives, further fueling innovation in the field.\\n9. Government support: Governments worldwide are recognizing the potential of ML and are providing funding and resources to support its development and adoption.\\n10. Exciting developments: The intersection of ML with other technologies like quantum computing, edge AI, and federated learning is leading to new and innovative applications that will continue to shape the field in the years to come.\\n\\nIn summary, Machine Learning is a hot topic due to its rapidly growing potential across various industries, improved accuracy, ethical considerations, advances in computational power, increased investment, government support, and exciting developments at the intersection of ML with other technologies.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is ML and why is it a hot topic?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
